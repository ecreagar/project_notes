{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# European Football Match Scraper\n",
    "> Downloading data for the maching learning model\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [soccer, machine learning, webscraping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The philosophy behind this model is this: people have been trying to figure out the best stat for predicting match outcomes for decades, we don't need to create something new. We can base the model on who has the best stats & probably get a great result. We'll also add in the odds from the casinos, but that's later.\n",
    "\n",
    "Right now, we need to download the stats for all those games. on [fbref.com](http://fbref.com), we see 122 different stats per team per game. Sometimes these are at the player level, sometimes at the team level. For this model, I am going to do all calculations at the team level. You'll see that we'll get a good result.\n",
    "\n",
    "This post is just the web scraper. The next post will build and train a model using the odds from the previous post and the matches from this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell processes the schedule pages since 2017 and grabs the links for each indivual match. Before 2017, the stats on fbref are different, not as complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6110 matches...\n"
     ]
    }
   ],
   "source": [
    "# Full stats for fbref.com seem to start in 2017\n",
    "sched_pages = [\n",
    "    \"https://fbref.com/en/comps/9/schedule/Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/1631/schedule/2017-2018-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/1889/schedule/2018-2019-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/9/3232/schedule/2019-2020-Premier-League-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/13/3243/schedule/2019-2020-Ligue-1-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/13/2104/schedule/2018-2019-Ligue-1-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/13/1632/schedule/2017-2018-Ligue-1-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/13/schedule/Ligue-1-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/20/3248/schedule/2019-2020-Bundesliga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/20/2109/schedule/2018-2019-Bundesliga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/20/1634/schedule/2017-2018-Bundesliga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/20/schedule/Bundesliga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/11/3260/schedule/2019-2020-Serie-A-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/11/1896/schedule/2018-2019-Serie-A-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/11/1640/schedule/2017-2018-Serie-A-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/11/schedule/Serie-A-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/12/3239/schedule/2019-2020-La-Liga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/12/1886/schedule/2018-2019-La-Liga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/12/1652/schedule/2017-2018-La-Liga-Scores-and-Fixtures\",\n",
    "    \"https://fbref.com/en/comps/12/chedule/La-Liga-Scores-and-Fixtures\",\n",
    "]\n",
    "match_pages = set()\n",
    "for s in sched_pages:\n",
    "    html = requests.get(s).text\n",
    "    match_url_regex = \"\\/en\\/matches\\/.{8}\\/[^\\\"]+\"\n",
    "    matches = re.findall(match_url_regex, html)\n",
    "    match_pages.update(matches)\n",
    "print(f\"found {len(match_pages)} matches...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the routine that parses the match data. The inline comments give some detail. There is an imporvement needed on to get the full data for the goalkeepers, if more than one is used in the match. This is a pretty rare event, so I haven't written the code to handle it yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match(html):\n",
    "    soup = bs(html, 'lxml')\n",
    "    match = {}\n",
    "    # get game data\n",
    "    match['game_id'] = url.split('/')[-1]\n",
    "    match['date'] = soup.find('span',{'class':'venuetime'})['data-venue-date']\n",
    "    match['game_time'] = soup.find('span',{'class':'venuetime'})['data-venue-time']\n",
    "    \n",
    "    # get scores\n",
    "    scorebox = soup.find('div',{'class':'scorebox'})\n",
    "    match['away_team'] = scorebox.findAll('div',{'itemprop':'performer'})[1].text.strip()\n",
    "    match['home_team'] = scorebox.findAll('div',{'itemprop':'performer'})[0].text.strip()\n",
    "    match['away_score'] = scorebox.findAll('div',{'class':'score'})[1].text.strip()\n",
    "    match['home_score'] = scorebox.findAll('div',{'class':'score'})[0].text.strip()\n",
    "    match['away_score_xg'] = scorebox.findAll('div',{'class':'score_xg'})[1].text.strip()\n",
    "    match['home_score_xg'] = scorebox.findAll('div',{'class':'score_xg'})[0].text.strip()\n",
    "    \n",
    "    # get stats from footers of stat tables\n",
    "    stat_table_regexes = [\n",
    "        'stats_.+_passing$',\n",
    "        'stats_.+_passing_types',\n",
    "        'stats_.+_defense',\n",
    "        'stats_.+_possession',\n",
    "        'stats_.+_misc'\n",
    "    ]\n",
    "    for p in stat_table_regexes:\n",
    "        tbls = soup.findAll('table',{'id':re.compile(p)})\n",
    "        # tbls[1] is the away team\n",
    "        for c in tbls[1].find('tfoot').findAll('td'):\n",
    "            if len(c.text)>0: match['away_'+c['data-stat']] = c.text\n",
    "        # tbls[0] is the home team\n",
    "        for c in tbls[0].find('tfoot').findAll('td'):\n",
    "            if len(c.text)>0: match['home_'+c['data-stat']] = c.text\n",
    "    \n",
    "    #goalkeeper stats from first row of goalkeepers (no summary row) \n",
    "    #TODO: get all goalkeepers in match if more than one\n",
    "    tbls = soup.findAll('table',{'id':re.compile('keeper_stats_')})\n",
    "    # tbls[1] is the away team\n",
    "    for c in tbls[1].findAll('tr')[2].findAll('td')[3:]: # skip the first 3 columns (name, age, country)\n",
    "        if len(c.text)>0: match['away_'+c['data-stat']] = c.text\n",
    "\n",
    "    # tbls[0] is the home team\n",
    "    for c in tbls[1].findAll('tr')[2].findAll('td')[3:]: # skip the first 3 columns (name, age, country)\n",
    "        if len(c.text)>0: match['home_'+c['data-stat']] = c.text\n",
    "    return match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the iterator to parse all of the matches. If there's an error parsing the match, it provides the link. Most of these are delayed matches. I haven't found any other types of problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 09:22:09.653225\n",
      "500 09:25:59.893262\n",
      "750 09:30:01.152984\n",
      "1000 09:34:28.578578\n",
      "1250 09:38:47.283655\n",
      "1500 09:43:17.526664\n",
      "1750 09:47:39.714315\n",
      "2000 09:51:46.943318\n",
      "2250 09:55:56.813498\n",
      "2500 09:59:37.172234\n",
      "2750 10:03:53.583911\n",
      "3000 10:07:55.117692\n",
      "3250 10:13:05.095473\n",
      "3500 10:18:18.249996\n",
      "3750 10:26:15.529503\n",
      "4000 10:37:23.986049\n",
      "4250 10:47:48.410901\n",
      "4500 10:57:33.316190\n",
      "4750 11:06:57.992304\n",
      "5000 11:16:44.733365\n",
      "5250 11:28:27.944883\n",
      "5500 11:40:59.823845\n",
      "5750 11:50:52.897307\n",
      "6000 12:00:06.576418\n"
     ]
    }
   ],
   "source": [
    "match_pages = list(match_pages)\n",
    "matches = []\n",
    "for m in match_pages:\n",
    "    url = 'https://fbref.com'+m\n",
    "    html = requests.get(url).text\n",
    "    try:\n",
    "        match = parse_match(html)\n",
    "    except:\n",
    "        # no advanced stats, or match was cancelled. Uncomment the below line to see examples\n",
    "        # print(url)\n",
    "        continue\n",
    "    matches.append(match)\n",
    "    if len(matches)%250==0: print(len(matches), dt.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we'll save the output to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6001, 251)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(matches)\n",
    "df.to_csv(\"matches.csv.gzip\", index=False, compression='gzip')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's 253 columns per match. It's a lot of stats... \n",
    "\n",
    "- 5 for game identification: game_id, date, time, home team and away team\n",
    "- 4 for score (score and score_xg, home and away)\n",
    "- 122 individual stats for each team\n",
    "\n",
    "I don't want to do a full EDA of this dataset in this notebook, but let's at least run a correlation to see which stats might be important. Starting with home team vs their score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"matches.csv.gzip\", compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_score                       1.000000\n",
       "home_goals_against_gk            0.989576\n",
       "home_assists                     0.844361\n",
       "home_psxg_gk                     0.762950\n",
       "home_save_pct                    0.614315\n",
       "home_score_xg                    0.592121\n",
       "home_shots_on_target_against     0.550086\n",
       "home_xa                          0.522682\n",
       "home_touches_att_pen_area        0.275894\n",
       "home_assisted_shots              0.272490\n",
       "home_through_balls               0.251706\n",
       "home_passes_completed_short      0.250673\n",
       "home_passes_pct                  0.245690\n",
       "home_passes_ground               0.238994\n",
       "home_passes_short                0.237699\n",
       "home_passes_pct_long             0.233341\n",
       "home_passes_completed            0.226572\n",
       "home_passes_received             0.226568\n",
       "home_passes_high                 0.214659\n",
       "home_carries                     0.213738\n",
       "home_pens_won                    0.211345\n",
       "home_pass_targets                0.210090\n",
       "home_touches_live_ball           0.208687\n",
       "home_passes_live                 0.207207\n",
       "home_passes_into_penalty_area    0.206309\n",
       "Name: home_score, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_columns = [x for x in df.columns if 'home' in x]\n",
    "df['home_score'] = pd.to_numeric(df['home_score'], errors='coerce')\n",
    "df[home_columns].corr()['home_score'].abs().sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "psxg_gk is \"Post-Shot Expected Goals\", a goalkeeper stat. Hover over the item on [fbref.com](http://fbref.com) to find out what each is.\n",
    "\n",
    "Also let's see what correlates with the away team score, in case its different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "away_score                          1.000000\n",
       "away_assists                        0.844739\n",
       "away_score_xg                       0.611637\n",
       "away_xa                             0.529720\n",
       "away_assisted_shots                 0.313385\n",
       "away_touches_att_pen_area           0.291722\n",
       "away_through_balls                  0.245553\n",
       "away_pens_won                       0.215357\n",
       "away_passes_into_penalty_area       0.201255\n",
       "away_passes_completed_short         0.179558\n",
       "away_passes_progressive_distance    0.172739\n",
       "away_passes_short                   0.170302\n",
       "away_touches_live_ball              0.163794\n",
       "away_passes_received                0.162729\n",
       "away_passes_completed               0.162645\n",
       "away_passes_pct                     0.161670\n",
       "away_passes_ground                  0.159949\n",
       "away_touches                        0.157365\n",
       "away_pass_targets                   0.152591\n",
       "away_passes_pct_long                0.150881\n",
       "away_passes_live                    0.149583\n",
       "away_carries                        0.145819\n",
       "away_passes_total_distance          0.144827\n",
       "away_passes_right_foot              0.144568\n",
       "away_passes                         0.142275\n",
       "Name: away_score, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "away_columns = [x for x in df.columns if 'away' in x]\n",
    "df['away_score'] = pd.to_numeric(df['away_score'], errors='coerce')\n",
    "df[away_columns].corr()['away_score'].abs().sort_values(ascending=False)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, but I'm much more interested in how a machine learning model feels about the stats. We'll do that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
