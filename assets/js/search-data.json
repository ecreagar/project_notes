{
  
    
        "post0": {
            "title": "MLB Model Optimization",
            "content": "In Part 3, our model was already performing better than the casino&#39;s oddsmakers, but it was only 0.6% better in accuracy and calibration was at parity. In this notebook, we&#39;ll get those numbers higher by doing some optimization of the hyperparameters and getting more data. . Get More Data . This is key to solving the overfitting problem we saw in Part 3. XGBoost wanting a low max_depth feels like a big deal to me, so let&#39;s solve it. I think of overfitting as a problem of either too many features or not enough data. I really love all the fancy and clever features we&#39;ve made, so let&#39;s get more data. . Start by going back to the blog post for Part 2 and run the whole thing again, except when you download from baseball-reference.com, start in 2013 instead fo 2016. The code to change is right under the header &quot;Create List of Games to Download&quot;. It might take a bit to download all that data. . ... I&#39;ll wait ... . Then re-run Part 3 to add the odds and power rankings to the dataset. . ... Go on ... . Done? Great. Let&#39;s get that new dataframe you saved into this notebook. Now we&#39;ll prepare it to be run by XGBoost in the same way we did in the last post, except that we&#39;re going to increase the size of the validation set from 500 games to 2500 games - a whole season of games. . import pickle df = pickle.load(open(&#39;dataframe_part3_big.pkl&#39;,&#39;rb&#39;)) # target encoding encode_me = [x for x in df.keys() if &#39;object&#39; in str(df[x].dtype)] for x in encode_me: df[x] = df.groupby(x)[&#39;home_team_win&#39;].apply(lambda x:x.rolling(180).mean()).shift(1) # create test, train splits df = df.sort_values(by=&#39;date&#39;).copy().reset_index(drop=True) X = df.drop(columns=[&#39;home_team_win&#39;, &#39;game_id&#39;]) y = df.home_team_win X_train = X[:-2500] y_train = y[:-2500] X_valid = X[-2500:-500] y_valid = y[-2500:-500] X_test = X[-500:] y_test = y[-500:] . Hyperparameter Optimization . For this post we&#39;ll use Hyperopt, a Baysean hyperparameter optimization tool. This will perform a search of the different parameters that we&#39;ll be feeding XGBoost to see which perform best. You can read on their website about how it works. . Install it like this pip install hyperopt . Below are the 3 functions I use to optimize XGBoost. The get_xgb_model function just trains the model, xgb_objective calls the first and does the model scoring, and get_xgbparams is the function that starts the hyperopt magic. . from hyperopt import fmin, tpe, hp, Trials import xgboost as xgb from sklearn.metrics import accuracy_score, brier_score_loss def get_xgb_model(params): # comment the next 2 lines out if you don&#39;t have gpu params[&#39;gpu_id&#39;] = 0 params[&#39;tree_method&#39;] = &#39;gpu_hist&#39; params[&#39;seed&#39;]=13 gbm = xgb.XGBClassifier(**params,n_estimators=999) model = gbm.fit(X_train, y_train, verbose=False, eval_set = [[X_train, y_train], [X_valid, y_valid]], eval_metric=&#39;logloss&#39;, early_stopping_rounds=15) return model def xgb_objective(params): params[&#39;max_depth&#39;]=int(params[&#39;max_depth&#39;]) model = get_xgb_model(params) xgb_test_proba = model.predict_proba(X_valid)[:,1] score = brier_score_loss(y_valid, xgb_test_proba) return(score) trials = Trials() # recorder for our results def get_xgbparams(space, evals=15): params = fmin(xgb_objective, space=space, algo=tpe.suggest, max_evals=evals, trials=trials) params[&#39;max_depth&#39;]=int(params[&#39;max_depth&#39;]) return params . Next we define the search space for hpyperopt and start the run. I won&#39;t go into the function of each of the hyperparameters, but I will give a shout out to this blog post - it&#39;s one of the best resources I&#39;ve seen on the subject. Most of the time I get good results in 250 runs, but if I&#39;m feeling thorough (and patient) I let it run for 2000 iterations. The space below could represent a million significantly different parameter combinations, so 250 trials might be putting too much faith in the search algorithm. . Let&#39;s do 1000 iterations and see what happens. . import numpy as np hyperopt_runs = 1000 space = { &#39;max_depth&#39;: hp.quniform(&#39;max_depth&#39;, 1, 8, 1), &#39;min_child_weight&#39;: hp.quniform(&#39;min_child_weight&#39;, 3, 15, 1), &#39;learning_rate&#39;: hp.loguniform(&#39;learning_rate&#39;, np.log(.01),np.log(.1)), &#39;subsample&#39;: hp.quniform(&#39;subsample&#39;, 0.2, 1.0,.2), &#39;colsample_bytree&#39;: hp.quniform(&#39;colsample_bytree&#39;, 0.2, 1.0,.2), &#39;reg_alpha&#39;: hp.loguniform(&#39;reg_alpha&#39;,np.log(1e-2),np.log(1e2)) } xgb_params = get_xgbparams(space,hyperopt_runs) xgb_params . 100%|██████████| 1000/1000 [2:55:11&lt;00:00, 10.51s/trial, best loss: 0.23426732326634775] . {&#39;colsample_bytree&#39;: 0.8, &#39;learning_rate&#39;: 0.03134186616692019, &#39;max_depth&#39;: 6, &#39;min_child_weight&#39;: 14.0, &#39;reg_alpha&#39;: 0.706883432815561, &#39;subsample&#39;: 0.4} . We just spent long time optimizing to the validation set and we found a very good set of parameters for it. That doesn&#39;t mean it&#39;s going to work well for the test set. But we&#39;ll cross our fingers anyway. . from sklearn.calibration import calibration_curve from sklearn.metrics import accuracy_score, brier_score_loss import matplotlib.pyplot as plt import pickle def cal_curve(data, bins): # adapted from: #https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html fig = plt.figure(1, figsize=(12, 8)) ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2) ax2 = plt.subplot2grid((3, 1), (2, 0)) ax1.plot([0, 1], [0, 1], &quot;k:&quot;, label=&quot;Perfectly calibrated&quot;) for y_test, y_pred, y_proba, name in data: brier = brier_score_loss(y_test, y_proba) print(&quot;{} t tAccuracy:{:.4f} t Brier Loss: {:.4f}&quot;.format( name, accuracy_score(y_test, y_pred), brier)) fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=bins) ax1.plot(mean_predicted_value, fraction_of_positives, label=&quot;%s (%1.4f)&quot; % (name, brier)) ax2.hist(y_proba, range=(0, 1), bins=bins, label=name, histtype=&quot;step&quot;, lw=2) ax1.set_ylabel(&quot;Fraction of positives&quot;) ax1.set_ylim([-0.05, 1.05]) ax1.legend(loc=&quot;lower right&quot;) ax1.set_title(&#39;Calibration plots (reliability curve)&#39;) ax2.set_xlabel(&quot;Mean predicted value&quot;) ax2.set_ylabel(&quot;Count&quot;) ax2.legend(loc=&quot;lower right&quot;) plt.tight_layout() plt.show() model = get_xgb_model(xgb_params) xgb_test_preds = model.predict(X_test) xgb_test_proba = model.predict_proba(X_test)[:,1] casino_proba = X_test[&#39;odds_proba&#39;] casino_preds = X_test[&#39;odds_proba&#39;]&gt;.5 data = [ (y_test, casino_preds, casino_proba, &#39;Casino&#39;), (y_test,xgb_test_preds, xgb_test_proba, &#39;XGBoost&#39;) ] cal_curve(data, 15) . . Casino Accuracy:0.5840 Brier Loss: 0.2398 XGBoost Accuracy:0.5740 Brier Loss: 0.2447 . Well that&#39;s not better. Even though our validation set had a brier_score_loss of 0.234, when we tried the same parameters on test it scores 0.247 - 5.6% worse. Let&#39;s print out our top hyperopt runs and see if the top one is an aberration. . import pandas as pd results = [] for i in range(len(trials.trials)): trial = trials.trials[i] inputs = trial[&#39;misc&#39;][&#39;vals&#39;] d = {} for key in inputs.keys(): d[key]=inputs[key][0] d[&#39;loss&#39;] = trials.losses()[i] results.append(d) pd.DataFrame(results).sort_values(by=&#39;loss&#39;)[:15] . colsample_bytree learning_rate max_depth min_child_weight reg_alpha subsample loss . 545 0.8 | 0.031342 | 6.0 | 14.0 | 0.706883 | 0.4 | 0.234267 | . 803 0.8 | 0.024690 | 7.0 | 11.0 | 0.227800 | 0.6 | 0.234566 | . 739 0.8 | 0.028251 | 7.0 | 12.0 | 0.828374 | 0.6 | 0.234669 | . 560 0.6 | 0.025124 | 6.0 | 12.0 | 0.524683 | 0.2 | 0.234754 | . 318 1.0 | 0.041507 | 7.0 | 7.0 | 5.616624 | 0.6 | 0.234871 | . 785 0.8 | 0.026125 | 7.0 | 11.0 | 0.336314 | 0.6 | 0.234902 | . 428 0.6 | 0.088649 | 3.0 | 10.0 | 2.052890 | 0.6 | 0.234911 | . 14 0.8 | 0.056913 | 7.0 | 11.0 | 11.230814 | 0.6 | 0.234926 | . 630 0.8 | 0.022215 | 7.0 | 12.0 | 8.019199 | 0.6 | 0.235049 | . 920 0.8 | 0.020671 | 7.0 | 9.0 | 1.259780 | 0.4 | 0.235057 | . 652 0.8 | 0.026317 | 7.0 | 11.0 | 0.537816 | 0.6 | 0.235098 | . 594 0.8 | 0.025847 | 7.0 | 12.0 | 0.470846 | 0.6 | 0.235106 | . 134 1.0 | 0.046117 | 6.0 | 6.0 | 3.851011 | 0.6 | 0.235160 | . 679 0.8 | 0.026523 | 7.0 | 11.0 | 22.084392 | 0.4 | 0.235162 | . 46 0.8 | 0.057895 | 2.0 | 12.0 | 0.820740 | 0.6 | 0.235167 | . It does look like our best run is an outlier, at least for min_child_weight. Let&#39;s take these insights and try to find a combination that translates to our test set. . params = { &#39;colsample_bytree&#39;:.7, &#39;learning_rate&#39;:.03, &#39;max_depth&#39;:7, &#39;min_child_weight&#39;:11, &#39;reg_alpha&#39;:0, &#39;subsample&#39;:.25 } model = get_xgb_model(params) xgb_test_preds = model.predict(X_test) xgb_test_proba = model.predict_proba(X_test)[:,1] casino_proba = X_test[&#39;odds_proba&#39;] casino_preds = X_test[&#39;odds_proba&#39;]&gt;.5 data = [ (y_test, casino_preds, casino_proba, &#39;Casino&#39;), (y_test,xgb_test_preds, xgb_test_proba, &#39;XGBoost&#39;) ] cal_curve(data, 15) . Casino Accuracy:0.5840 Brier Loss: 0.2398 XGBoost Accuracy:0.6060 Brier Loss: 0.2383 . I get pretty obsessive about hyperparameter adjustments. It&#39;s like a little game that I can&#39;t stop playing. I am just going to stop. This is good. . We&#39;ve got a model that &gt;2% better than the casino&#39;s and just as well calibrated. The last thing I want to check is how closely our predictions are correlated to the casino&#39;s. The lower the correlation, the more bets we&#39;ll get to place. . from sklearn.metrics import r2_score r2_score(casino_proba, xgb_test_proba) . 0.681159153310547 . That&#39;s great news. It looks like it&#39;s going to give us a lot of opportunities to bet. Let&#39;s save our model. We&#39;ll use it in Part 5. . import pickle pickle.dump(model,open(&#39;xgb_model.pkl&#39;,&#39;wb&#39;)) . Next Up . Part 5. Time move on to figuring out how to generate predictions and place bets. We&#39;ll use the Kelly criterion. .",
            "url": "https://rdpharr.github.io/project_notes/baseball/hyperopt/xgboost/2020/09/24/model-optimization.html",
            "relUrl": "/baseball/hyperopt/xgboost/2020/09/24/model-optimization.html",
            "date": " • Sep 24, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "MLB Power Rankings and Casino Odds",
            "content": "Last time, we created a model that performs pretty well just based on the statistics that we downloaded from baseball-reference.com. In this post, we&#39;ll extend that model by adding power rankings and casino odds to the model. . Important: You can run this notebook from Colab or Binder using the buttons above, but you&#8217;ll also need the files we created in Part 2. . Power Rankings . The 538 Blog has famously modified the Elo system from chess to make their baseball rankings. The Elo system tries to determine the relative skill level of a player based on the skill levels of the other players encountered. If you beat a person with a high skill level, your skill level is going to improve more than if you win against a player of the same or lower skill level than you. And if your skill level is higher than your opponent&#39;s then you will probably win the match. . If 538 thinks Elo is foundational, then we should definitely put it in our model. The trouble is that not everyone agrees on how to implement it. In fact there are a whole family of different power ranking systems out there. In this project we&#39;re going to add four: 2 varieties of Elo (slow and fast changing), Glicko, and Trueskill. Luckily people have created libraries to help us get the code right. . Important: If you are running this notebook online, you may need to install the additional libraries. Here&#8217;s how to do it on Colab. . Let&#39;s get to it. We&#39;ll start by importing our dataframe from Part 2. . import pickle df = pickle.load(open(&quot;dataframe.pkl&quot;,&quot;rb&quot;)) . Elo Rankings . For Elo rankings, we&#39;re going to use the elote library, primarily because it&#39;s named after the Mexican habit of eating corn on the cob with mayonnaise (yuck!). Install it like this: . pip install elote . from elote import EloCompetitor ratings = {} for x in df.home_team_abbr.unique(): ratings[x]=EloCompetitor() for x in df.away_team_abbr.unique(): ratings[x]=EloCompetitor() home_team_elo = [] away_team_elo = [] elo_exp = [] df = df.sort_values(by=&#39;date&#39;).reset_index(drop=True) for i, r in df.iterrows(): # get pre-game ratings elo_exp.append(ratings[r.home_team_abbr].expected_score(ratings[r.away_team_abbr])) home_team_elo.append(ratings[r.home_team_abbr].rating) away_team_elo.append(ratings[r.away_team_abbr].rating) # update ratings if r.home_team_win: ratings[r.home_team_abbr].beat(ratings[r.away_team_abbr]) else: ratings[r.away_team_abbr].beat(ratings[r.home_team_abbr]) df[&#39;elo_exp&#39;] = elo_exp df[&#39;home_team_elo&#39;] = home_team_elo df[&#39;away_team_elo&#39;] = away_team_elo . Now we&#39;ll do the slow changing version, where we decrease the k-factor. . ratings = {} for x in df.home_team_abbr.unique(): ratings[x]=EloCompetitor() ratings[x]._k_score=16 for x in df.away_team_abbr.unique(): ratings[x]=EloCompetitor() ratings[x]._k_score=16 home_team_elo = [] away_team_elo = [] elo_exp = [] df = df.sort_values(by=&#39;date&#39;).reset_index(drop=True) for i, r in df.iterrows(): # get pregame ratings elo_exp.append(ratings[r.home_team_abbr].expected_score(ratings[r.away_team_abbr])) home_team_elo.append(ratings[r.home_team_abbr].rating) away_team_elo.append(ratings[r.away_team_abbr].rating) # update ratings if r.home_team_win: ratings[r.home_team_abbr].beat(ratings[r.away_team_abbr]) else: ratings[r.away_team_abbr].beat(ratings[r.home_team_abbr]) df[&#39;elo_slow_exp&#39;] = elo_exp df[&#39;home_team_elo_slow&#39;] = home_team_elo df[&#39;away_team_elo_slow&#39;] = away_team_elo . Glicko Ratings . Glicko can be calculated using the same library. . from elote import GlickoCompetitor ratings = {} for x in df.home_team_abbr.unique(): ratings[x]=GlickoCompetitor() for x in df.away_team_abbr.unique(): ratings[x]=GlickoCompetitor() home_team_glick = [] away_team_glick = [] glick_exp = [] df = df.sort_values(by=&#39;date&#39;).reset_index(drop=True) for i, r in df.iterrows(): # get pregame ratings glick_exp.append(ratings[r.home_team_abbr].expected_score(ratings[r.away_team_abbr])) home_team_glick.append(ratings[r.home_team_abbr].rating) away_team_glick.append(ratings[r.away_team_abbr].rating) # update ratings if r.home_team_win: ratings[r.home_team_abbr].beat(ratings[r.away_team_abbr]) else: ratings[r.away_team_abbr].beat(ratings[r.home_team_abbr]) df[&#39;glick_exp&#39;] = glick_exp df[&#39;home_team_glick&#39;] = home_team_glick df[&#39;away_team_glick&#39;] = away_team_glick . Trueskill Ratings . Trueskill was invented for Microsoft video games on the XBox. It&#39;s something you need to license if you are going to use it for commercial purposes. Trueskill ratings are a little bit more complex, because we have the opportunity to include the starting pitcher skill as well. Install the python package like this: . pip install trueskill . from trueskill import Rating, quality, rate ratings = {} for x in df.home_team_abbr.unique(): ratings[x]=Rating(25) for x in df.away_team_abbr.unique(): ratings[x]=Rating(25) for x in df.home_pitcher.unique(): ratings[x]=Rating(25) for x in df.away_pitcher.unique(): ratings[x]=Rating(25) ts_quality = [] pitcher_ts_diff = [] team_ts_diff = [] home_pitcher_ts = [] away_pitcher_ts = [] home_team_ts = [] away_team_ts = [] df = df.sort_values(by=&#39;date&#39;).copy() for i, r in df.iterrows(): # get pre-match trueskill ratings from dict match = [(ratings[r.home_team_abbr], ratings[r.home_pitcher]), (ratings[r.away_team_abbr], ratings[r.away_pitcher])] ts_quality.append(quality(match)) pitcher_ts_diff.append(ratings[r.home_pitcher].mu-ratings[r.away_pitcher].mu) team_ts_diff.append(ratings[r.home_team_abbr].mu-ratings[r.away_team_abbr].mu) home_pitcher_ts.append(ratings[r.home_pitcher].mu) away_pitcher_ts.append(ratings[r.away_pitcher].mu) home_team_ts.append(ratings[r.home_team_abbr].mu) away_team_ts.append(ratings[r.away_team_abbr].mu) if r.date &lt; df.date.max(): # update ratings dictionary with post-match ratings if r.home_team_win==1: match = [(ratings[r.home_team_abbr], ratings[r.home_pitcher]), (ratings[r.away_team_abbr], ratings[r.away_pitcher])] [(ratings[r.home_team_abbr], ratings[r.home_pitcher]), (ratings[r.away_team_abbr], ratings[r.away_pitcher])] = rate(match) else: match = [(ratings[r.away_team_abbr], ratings[r.away_pitcher]), (ratings[r.home_team_abbr], ratings[r.home_pitcher])] [(ratings[r.away_team_abbr], ratings[r.away_pitcher]), (ratings[r.home_team_abbr], ratings[r.home_pitcher])] = rate(match) df[&#39;ts_game_quality&#39;] = ts_quality df[&#39;pitcher_ts_diff&#39;] = pitcher_ts_diff df[&#39;team_ts_diff&#39;] = team_ts_diff df[&#39;home_pitcher_ts&#39;] = home_pitcher_ts df[&#39;away_pitcher_ts&#39;] = away_pitcher_ts df[&#39;home_team_ts&#39;] = home_team_ts df[&#39;away_team_ts&#39;] = away_team_ts . That&#39;s all we need for power rankings. Let&#39;s move on. . Casino Odds . Having the casino odds in our model is really going to improve its predictions, but getting them in there is kind of a pain in the ass. The problem is that we need to match the games from two different systems (baseball-reference.com and covers.com). These systems don&#39;t use the same team abbreviations and don&#39;t even agree on what time the games started. So there&#39;s a bit of code to compensate. . But it starts the same as in Part 1 of this blog series - we need to find out which days to download odds data for. We&#39;ll use our dataframe to get this list. . import pandas as pd dates = pd.to_datetime(df[&#39;date&#39;], unit=&#39;s&#39;) game_days = dates.dt.strftime(&#39;%Y-%m-%d&#39;).unique() print(&quot;Days of odds data needed:&quot;, len(game_days)) . Days of odds data needed: 885 . The below code is largely the same from Part 1, except we are also grabbing team abbreviations from the data . import requests from bs4 import BeautifulSoup as bs import datetime as dt game_data = [] for d in game_days: # get the web page with game data on it url = f&#39;https://www.covers.com/Sports/MLB/Matchups?selectedDate={d}&#39; resp = requests.get(url) # parse the games scraped_games = bs(resp.text).findAll(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_game_box&#39;}) for g in scraped_games: game = {} game[&#39;home_moneyline&#39;] = g[&#39;data-game-odd&#39;] game[&#39;date&#39;] = g[&#39;data-game-date&#39;] game[&#39;away_team_abbr&#39;] = g[&#39;data-away-team-shortname-search&#39;] game[&#39;home_team_abbr&#39;] = g[&#39;data-home-team-shortname-search&#39;] try: game[&#39;home_score&#39;] =g.find(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_list_score_home&#39;}).text.strip() game[&#39;away_score&#39;] =g.find(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_list_score_away&#39;}).text.strip() except: game[&#39;home_score&#39;] =&#39;&#39; game[&#39;away_score&#39;] =&#39;&#39; game_data.append(game) if len(game_data) % 1000==0: #show progress print(dt.datetime.now(), d, len(game_data)) print(&quot;Done! Games downloaded:&quot;, len(game_data)) . 2020-09-23 16:52:21.794853 2016-06-15 1000 2020-09-23 16:53:17.556900 2016-08-31 2000 2020-09-23 16:54:28.987126 2017-05-10 3000 2020-09-23 16:55:25.810966 2017-07-24 4000 2020-09-23 16:56:35.138059 2018-03-29 5000 2020-09-23 16:57:33.919756 2018-06-10 6000 2020-09-23 16:58:54.173907 2018-08-26 7000 2020-09-23 17:00:18.965869 2019-05-01 8000 2020-09-23 17:01:23.090361 2019-07-17 9000 2020-09-23 17:02:27.603102 2019-09-29 10000 Done! Games downloaded: 10941 . So slow. Let&#39;s save this so we don&#39;t have to go through that again. . import pickle pickle.dump(game_data, open(&#39;covers_data_2.pkl&#39;,&#39;wb&#39;)) . We&#39;ll do some prepping and cleaning of the data. . import pickle game_data = pickle.load(open(&#39;covers_data_2.pkl&#39;,&#39;rb&#39;)) . import numpy as np import pandas as pd odds = pd.DataFrame(game_data) odds[&#39;home_moneyline&#39;].replace(&#39;&#39;, np.nan, inplace=True) odds.dropna(subset=[&#39;home_moneyline&#39;], inplace=True) odds.home_moneyline = pd.to_numeric(odds.home_moneyline) odds.date = pd.to_datetime(odds.date).dt.date . Now we convert the team names to be the same as baseball-reference.com . import warnings warnings.filterwarnings(&#39;ignore&#39;) warnings.simplefilter(action=&#39;ignore&#39;, category=FutureWarning) odds.home_team_abbr[odds.home_team_abbr==&#39;SF&#39;]=&#39;SFG&#39; odds.home_team_abbr[odds.home_team_abbr==&#39;TB&#39;]=&#39;TBR&#39; odds.home_team_abbr[odds.home_team_abbr==&#39;WAS&#39;]=&#39;WSN&#39; odds.home_team_abbr[odds.home_team_abbr==&#39;KC&#39;]=&#39;KCR&#39; odds.home_team_abbr[odds.home_team_abbr==&#39;SD&#39;]=&#39;SDP&#39; odds.away_team_abbr[odds.away_team_abbr==&#39;SF&#39;]=&#39;SFG&#39; odds.away_team_abbr[odds.away_team_abbr==&#39;TB&#39;]=&#39;TBR&#39; odds.away_team_abbr[odds.away_team_abbr==&#39;WAS&#39;]=&#39;WSN&#39; odds.away_team_abbr[odds.away_team_abbr==&#39;KC&#39;]=&#39;KCR&#39; odds.away_team_abbr[odds.away_team_abbr==&#39;SD&#39;]=&#39;SDP&#39; . Finally, convert the moneyline odds to probabilities . odds[&#39;odds_proba&#39;]=np.nan odds[&#39;odds_proba&#39;][odds.home_moneyline&lt;0] = -odds.home_moneyline/(-odds.home_moneyline + 100) odds[&#39;odds_proba&#39;][odds.home_moneyline&gt;0] = (100/(odds.home_moneyline + 100)) . Because the game times aren&#39;t exact, we&#39;ll use pandas merge_asof to find the closest match. The syntax is that you the fields in &quot;by&quot; parameter need to be exact, and it will find the closest by the &quot;on&quot; parameter. I think this feature is awesome, and another reason I love pandas. . print(&#39;dataframe shape before merge:&#39;, df.shape) # get dates into the same format odds[&#39;date&#39;] = (pd.to_datetime(pd.to_datetime(odds[&#39;date&#39;])) - pd.Timestamp(&quot;1970-01-01&quot;)) // pd.Timedelta(&#39;1s&#39;) # do the merge df = pd.merge_asof(left=df.sort_values(by=&#39;date&#39;), right=odds[[&#39;home_team_abbr&#39;,&#39;date&#39;, &#39;away_team_abbr&#39;,&#39;odds_proba&#39;]].sort_values(by=&#39;date&#39;), by=[&#39;home_team_abbr&#39;,&#39;away_team_abbr&#39;], on=&#39;date&#39;) df = df.sort_values(by=&#39;date&#39;).copy().reset_index(drop=True) print(&#39;dataframe shape after merge:&#39;, df.shape) . dataframe shape before merge: (10535, 1052) dataframe shape after merge: (10535, 1053) . Things look good now. Let&#39;s save this dataframe before we move on . import pickle pickle.dump(df, open(&#39;dataframe_part3.pkl&#39;,&#39;wb&#39;)) . Run The Model . This is almost the exact code we ran in part 2 . import pickle df = pickle.load(open(&#39;dataframe_part3.pkl&#39;,&#39;rb&#39;)) . import xgboost as xgb # target encoding encode_me = [x for x in df.keys() if &#39;object&#39; in str(df[x].dtype)] for x in encode_me: df[x] = df.groupby(x)[&#39;home_team_win&#39;].apply(lambda x:x.rolling(180).mean()).shift(1) # create test, train splits df = df.sort_values(by=&#39;date&#39;).copy().reset_index(drop=True) X = df.drop(columns=[&#39;home_team_win&#39;, &#39;game_id&#39;]) y = df.home_team_win X_train = X[:-1000] y_train = y[:-1000] X_valid = X[-1000:-500] y_valid = y[-1000:-500] X_test = X[-500:] y_test = y[-500:] . Run the model . params = {&#39;learning_rate&#39;: 0.035,&#39;max_depth&#39;: 1} gbm = xgb.XGBClassifier(**params) model = gbm.fit(X_train, y_train, eval_set = [[X_train, y_train], [X_valid, y_valid]], eval_metric=&#39;logloss&#39;, early_stopping_rounds=10) xgb_test_preds = model.predict(X_test) xgb_test_proba = model.predict_proba(X_test)[:,1] . [0] validation_0-logloss:0.69210 validation_1-logloss:0.69159 Multiple eval metrics have been passed: &#39;validation_1-logloss&#39; will be used for early stopping. Will train until validation_1-logloss hasn&#39;t improved in 10 rounds. [1] validation_0-logloss:0.69111 validation_1-logloss:0.69047 [2] validation_0-logloss:0.69019 validation_1-logloss:0.68902 [3] validation_0-logloss:0.68932 validation_1-logloss:0.68802 [4] validation_0-logloss:0.68850 validation_1-logloss:0.68670 [5] validation_0-logloss:0.68773 validation_1-logloss:0.68580 [6] validation_0-logloss:0.68699 validation_1-logloss:0.68471 [7] validation_0-logloss:0.68630 validation_1-logloss:0.68360 [8] validation_0-logloss:0.68564 validation_1-logloss:0.68261 [9] validation_0-logloss:0.68502 validation_1-logloss:0.68188 [10] validation_0-logloss:0.68443 validation_1-logloss:0.68097 [11] validation_0-logloss:0.68385 validation_1-logloss:0.68031 [12] validation_0-logloss:0.68332 validation_1-logloss:0.67944 [13] validation_0-logloss:0.68279 validation_1-logloss:0.67883 [14] validation_0-logloss:0.68230 validation_1-logloss:0.67825 [15] validation_0-logloss:0.68183 validation_1-logloss:0.67750 [16] validation_0-logloss:0.68137 validation_1-logloss:0.67700 [17] validation_0-logloss:0.68094 validation_1-logloss:0.67663 [18] validation_0-logloss:0.68052 validation_1-logloss:0.67595 [19] validation_0-logloss:0.68012 validation_1-logloss:0.67521 [20] validation_0-logloss:0.67974 validation_1-logloss:0.67488 [21] validation_0-logloss:0.67937 validation_1-logloss:0.67428 [22] validation_0-logloss:0.67902 validation_1-logloss:0.67389 [23] validation_0-logloss:0.67869 validation_1-logloss:0.67324 [24] validation_0-logloss:0.67837 validation_1-logloss:0.67297 [25] validation_0-logloss:0.67806 validation_1-logloss:0.67245 [26] validation_0-logloss:0.67776 validation_1-logloss:0.67209 [27] validation_0-logloss:0.67748 validation_1-logloss:0.67178 [28] validation_0-logloss:0.67720 validation_1-logloss:0.67133 [29] validation_0-logloss:0.67694 validation_1-logloss:0.67102 [30] validation_0-logloss:0.67669 validation_1-logloss:0.67060 [31] validation_0-logloss:0.67644 validation_1-logloss:0.67038 [32] validation_0-logloss:0.67621 validation_1-logloss:0.67012 [33] validation_0-logloss:0.67598 validation_1-logloss:0.66963 [34] validation_0-logloss:0.67576 validation_1-logloss:0.66926 [35] validation_0-logloss:0.67554 validation_1-logloss:0.66903 [36] validation_0-logloss:0.67534 validation_1-logloss:0.66904 [37] validation_0-logloss:0.67514 validation_1-logloss:0.66879 [38] validation_0-logloss:0.67494 validation_1-logloss:0.66844 [39] validation_0-logloss:0.67476 validation_1-logloss:0.66821 [40] validation_0-logloss:0.67458 validation_1-logloss:0.66824 [41] validation_0-logloss:0.67440 validation_1-logloss:0.66801 [42] validation_0-logloss:0.67423 validation_1-logloss:0.66771 [43] validation_0-logloss:0.67406 validation_1-logloss:0.66755 [44] validation_0-logloss:0.67390 validation_1-logloss:0.66737 [45] validation_0-logloss:0.67374 validation_1-logloss:0.66729 [46] validation_0-logloss:0.67359 validation_1-logloss:0.66719 [47] validation_0-logloss:0.67344 validation_1-logloss:0.66708 [48] validation_0-logloss:0.67329 validation_1-logloss:0.66713 [49] validation_0-logloss:0.67315 validation_1-logloss:0.66707 [50] validation_0-logloss:0.67302 validation_1-logloss:0.66689 [51] validation_0-logloss:0.67288 validation_1-logloss:0.66676 [52] validation_0-logloss:0.67275 validation_1-logloss:0.66660 [53] validation_0-logloss:0.67262 validation_1-logloss:0.66656 [54] validation_0-logloss:0.67250 validation_1-logloss:0.66644 [55] validation_0-logloss:0.67238 validation_1-logloss:0.66635 [56] validation_0-logloss:0.67226 validation_1-logloss:0.66641 [57] validation_0-logloss:0.67214 validation_1-logloss:0.66628 [58] validation_0-logloss:0.67203 validation_1-logloss:0.66614 [59] validation_0-logloss:0.67192 validation_1-logloss:0.66612 [60] validation_0-logloss:0.67182 validation_1-logloss:0.66599 [61] validation_0-logloss:0.67171 validation_1-logloss:0.66591 [62] validation_0-logloss:0.67161 validation_1-logloss:0.66578 [63] validation_0-logloss:0.67151 validation_1-logloss:0.66569 [64] validation_0-logloss:0.67142 validation_1-logloss:0.66567 [65] validation_0-logloss:0.67132 validation_1-logloss:0.66575 [66] validation_0-logloss:0.67123 validation_1-logloss:0.66582 [67] validation_0-logloss:0.67114 validation_1-logloss:0.66571 [68] validation_0-logloss:0.67105 validation_1-logloss:0.66577 [69] validation_0-logloss:0.67096 validation_1-logloss:0.66594 [70] validation_0-logloss:0.67088 validation_1-logloss:0.66593 [71] validation_0-logloss:0.67079 validation_1-logloss:0.66582 [72] validation_0-logloss:0.67071 validation_1-logloss:0.66575 [73] validation_0-logloss:0.67063 validation_1-logloss:0.66565 [74] validation_0-logloss:0.67055 validation_1-logloss:0.66571 [75] validation_0-logloss:0.67048 validation_1-logloss:0.66578 [76] validation_0-logloss:0.67040 validation_1-logloss:0.66594 [77] validation_0-logloss:0.67033 validation_1-logloss:0.66598 [78] validation_0-logloss:0.67025 validation_1-logloss:0.66589 [79] validation_0-logloss:0.67018 validation_1-logloss:0.66595 [80] validation_0-logloss:0.67011 validation_1-logloss:0.66587 [81] validation_0-logloss:0.67005 validation_1-logloss:0.66573 [82] validation_0-logloss:0.66998 validation_1-logloss:0.66580 [83] validation_0-logloss:0.66991 validation_1-logloss:0.66585 Stopping. Best iteration: [73] validation_0-logloss:0.67063 validation_1-logloss:0.66565 . Since we now know the casino odds for these specific games, we can directly compare our model preditions with on the same games. Peviously we&#39;d been comparing our results against how the casino predicted 2019 games. . from sklearn.calibration import calibration_curve from sklearn.metrics import accuracy_score, brier_score_loss import matplotlib.pyplot as plt import pickle def cal_curve(data, bins): # adapted from: #https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html fig = plt.figure(1, figsize=(12, 8)) ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2) ax2 = plt.subplot2grid((3, 1), (2, 0)) ax1.plot([0, 1], [0, 1], &quot;k:&quot;, label=&quot;Perfectly calibrated&quot;) for y_test, y_pred, y_proba, name in data: brier = brier_score_loss(y_test, y_proba) print(&quot;{} t tAccuracy:{:.4f} t Brier Loss: {:.4f}&quot;.format( name, accuracy_score(y_test, y_pred), brier)) fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=bins) ax1.plot(mean_predicted_value, fraction_of_positives, label=&quot;%s (%1.4f)&quot; % (name, brier)) ax2.hist(y_proba, range=(0, 1), bins=bins, label=name, histtype=&quot;step&quot;, lw=2) ax1.set_ylabel(&quot;Fraction of positives&quot;) ax1.set_ylim([-0.05, 1.05]) ax1.legend(loc=&quot;lower right&quot;) ax1.set_title(&#39;Calibration plots (reliability curve)&#39;) ax2.set_xlabel(&quot;Mean predicted value&quot;) ax2.set_ylabel(&quot;Count&quot;) ax2.legend(loc=&quot;lower right&quot;) plt.tight_layout() plt.show() casino_proba = X_test[&#39;odds_proba&#39;] casino_preds = X_test[&#39;odds_proba&#39;]&gt;.5 data = [ (y_test, casino_preds, casino_proba, &#39;Casino&#39;), (y_test,xgb_test_preds, xgb_test_proba, &#39;XGBoost&#39;) ] cal_curve(data, 15) . . Casino Accuracy:0.5840 Brier Loss: 0.2401 XGBoost Accuracy:0.5900 Brier Loss: 0.2406 . Now we&#39;re talking. Our accuracy in our test data is 0.6% better than the oddsmakers and our calibration is virtually the same. It&#39;s a concern that to get these results, I needed to set the max depth to 1. That is very low, and implies that we are susceptible to overfitting. One way to fix that is to get more data... . Next up . In Part 4, we&#39;re going to train this thing for real, and try to squeak out a few more % through downloading more data and hyperparameter optimization. You may want to run the next notebook overnight... .",
            "url": "https://rdpharr.github.io/project_notes/baseball/webscraping/elo/trueskill/glick/2020/09/22/power-rankings-and-casino-odds.html",
            "relUrl": "/baseball/webscraping/elo/trueskill/glick/2020/09/22/power-rankings-and-casino-odds.html",
            "date": " • Sep 22, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "MLB Training Data",
            "content": "This is the second post in my series on MLB Baseball Betting, and it&#39;s a long one. Here we&#39;re going to have a complete working model from scraping the data, processing it, adding features and finally giving it a run in XGBoost. . This is all done in a single notebook so you can start fiddling with it on your own as soon as you want. Use the buttons on the top to download your own copy from github or run it in the cloud on one of the services listed. . Scrape Data . For this model, I&#39;m going to use the stats from the baseball-reference.com box scores page. Here is and example of the page we&#39;ll be scraping. Let&#39;s get started. . Create List of Games to Download . We&#39;ll get the games from the schedule pages, creating a list of links to each game. Let&#39;s start in 2016, that should give us enough games to start making inferences. . import requests from bs4 import BeautifulSoup as bs game_links = [] for current_year in range(2016,2021): url = f&quot;https://www.baseball-reference.com/leagues/MLB/{current_year}-schedule.shtml&quot; resp = requests.get(url) soup=bs(resp.text) games = soup.findAll(&#39;a&#39;,text=&#39;Boxscore&#39;) game_links.extend([x[&#39;href&#39;] for x in games]) print(&quot;Number of games to download: &quot;, len(game_links)) game_links[0] . Number of games to download: 10684 . &#39;/boxes/KCA/KCA201604030.shtml&#39; . Download Game Data . For each game, I want to download team performance in batting and pitching, as well as individual performance pitching. For 10K games, this is going to take a little while to build out. . # these are functions related to parsing the baseball reference page def get_game_summary(soup, game_id): game = {&#39;game_id&#39;: game_id} scorebox = soup.find(&#39;div&#39;, {&#39;class&#39;:&#39;scorebox&#39;}) teams = scorebox.findAll(&#39;a&#39;,{&#39;itemprop&#39;:&#39;name&#39;}) game[&#39;away_team_abbr&#39;] = teams[0][&#39;href&#39;].split(&#39;/&#39;)[2] game[&#39;home_team_abbr&#39;] = teams[1][&#39;href&#39;].split(&#39;/&#39;)[2] meta = scorebox.find(&#39;div&#39;, {&#39;class&#39;:&#39;scorebox_meta&#39;}).findAll(&#39;div&#39;) game[&#39;date&#39;] = meta[0].text.strip() game[&#39;start_time&#39;] = meta[1].text[12:-6].strip() return game def get_table_summary(soup, table_no): stats_tables = soup.findAll(&#39;table&#39;, {&#39;class&#39;:&#39;stats_table&#39;}) t = stats_tables[table_no].find(&#39;tfoot&#39;) summary = {x[&#39;data-stat&#39;]:x.text.strip() for x in t.findAll(&#39;td&#39;)} return summary def get_pitcher_data(soup, table_no): stats_tables = soup.findAll(&#39;table&#39;, {&#39;class&#39;:&#39;stats_table&#39;}) t = stats_tables[table_no] data = [] rows = t.findAll(&#39;tr&#39;)[1:-1] # not the header and footer rows for r in rows: summary = {x[&#39;data-stat&#39;]:x.text.strip() for x in r.findAll(&#39;td&#39;)} summary[&#39;name&#39;] = r.find(&#39;th&#39;,{&#39;data-stat&#39;:&#39;player&#39;}).find(&#39;a&#39;)[&#39;href&#39;].split(&#39;/&#39;)[-1][:-6].strip() data.append(summary) return data def process_link(url): resp = requests.get(url) game_id = url.split(&#39;/&#39;)[-1][:-6] # strange preprocessing routine uncommented_html = &#39;&#39; for h in resp.text.split(&#39; n&#39;): if &#39;&lt;!-- &lt;div&#39; in h: continue if h.strip() == &#39;&lt;!--&#39;: continue if h.strip() == &#39;--&gt;&#39;: continue uncommented_html += h + &#39; n&#39; soup = bs(uncommented_html) data = { &#39;game&#39;: get_game_summary(soup, game_id), &#39;away_batting&#39;: get_table_summary(soup, 1), &#39;home_batting&#39;:get_table_summary(soup, 2), &#39;away_pitching&#39;:get_table_summary(soup, 3), &#39;home_pitching&#39;:get_table_summary(soup, 4), &#39;away_pitchers&#39;: get_pitcher_data(soup, 3), &#39;home_pitchers&#39;: get_pitcher_data(soup, 4) } return data . . import datetime as dt game_data = [] for link in game_links: url = &#39;https://www.baseball-reference.com&#39; + link game_data.append(process_link(url)) if len(game_data)%1000==0: print(dt.datetime.now().time(), len(game_data)) . 14:24:15.188000 1000 14:34:20.590050 2000 14:44:37.326441 3000 14:54:50.018196 4000 15:05:12.944858 5000 15:15:18.664457 6000 15:25:07.445247 7000 15:35:07.049830 8000 15:44:55.807973 9000 15:54:50.771393 10000 . That took a while. We could definitely speed it up with threading, but we want to be nice to their servers. They seem like good people, making their data available to everyone. . Here is what a single game looks like. It&#39;s actually quite a bit of data. . game_data[0] . {&#39;game&#39;: {&#39;game_id&#39;: &#39;KCA201604030&#39;, &#39;away_team_abbr&#39;: &#39;NYM&#39;, &#39;home_team_abbr&#39;: &#39;KCR&#39;, &#39;date&#39;: &#39;Sunday, April 3, 2016&#39;, &#39;start_time&#39;: &#39;7:38 p.m.&#39;}, &#39;away_batting&#39;: {&#39;AB&#39;: &#39;33&#39;, &#39;R&#39;: &#39;3&#39;, &#39;H&#39;: &#39;7&#39;, &#39;RBI&#39;: &#39;3&#39;, &#39;BB&#39;: &#39;6&#39;, &#39;SO&#39;: &#39;9&#39;, &#39;PA&#39;: &#39;39&#39;, &#39;batting_avg&#39;: &#39;.212&#39;, &#39;onbase_perc&#39;: &#39;.333&#39;, &#39;slugging_perc&#39;: &#39;.242&#39;, &#39;onbase_plus_slugging&#39;: &#39;.576&#39;, &#39;pitches&#39;: &#39;177&#39;, &#39;strikes_total&#39;: &#39;105&#39;, &#39;wpa_bat&#39;: &#39;-0.449&#39;, &#39;leverage_index_avg&#39;: &#39;1.58&#39;, &#39;wpa_bat_pos&#39;: &#39;0.746&#39;, &#39;wpa_bat_neg&#39;: &#39;-1.195&#39;, &#39;re24_bat&#39;: &#39;-1.7&#39;, &#39;PO&#39;: &#39;24&#39;, &#39;A&#39;: &#39;15&#39;, &#39;details&#39;: &#39;&#39;}, &#39;home_batting&#39;: {&#39;AB&#39;: &#39;30&#39;, &#39;R&#39;: &#39;4&#39;, &#39;H&#39;: &#39;9&#39;, &#39;RBI&#39;: &#39;4&#39;, &#39;BB&#39;: &#39;2&#39;, &#39;SO&#39;: &#39;3&#39;, &#39;PA&#39;: &#39;33&#39;, &#39;batting_avg&#39;: &#39;.300&#39;, &#39;onbase_perc&#39;: &#39;.333&#39;, &#39;slugging_perc&#39;: &#39;.300&#39;, &#39;onbase_plus_slugging&#39;: &#39;.633&#39;, &#39;pitches&#39;: &#39;114&#39;, &#39;strikes_total&#39;: &#39;71&#39;, &#39;wpa_bat&#39;: &#39;0.052&#39;, &#39;leverage_index_avg&#39;: &#39;0.74&#39;, &#39;wpa_bat_pos&#39;: &#39;0.488&#39;, &#39;wpa_bat_neg&#39;: &#39;-0.434&#39;, &#39;re24_bat&#39;: &#39;-0.1&#39;, &#39;PO&#39;: &#39;27&#39;, &#39;A&#39;: &#39;13&#39;, &#39;details&#39;: &#39;&#39;}, &#39;away_pitching&#39;: {&#39;IP&#39;: &#39;8&#39;, &#39;H&#39;: &#39;9&#39;, &#39;R&#39;: &#39;4&#39;, &#39;ER&#39;: &#39;3&#39;, &#39;BB&#39;: &#39;2&#39;, &#39;SO&#39;: &#39;3&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;3.38&#39;, &#39;batters_faced&#39;: &#39;33&#39;, &#39;pitches&#39;: &#39;114&#39;, &#39;strikes_total&#39;: &#39;71&#39;, &#39;strikes_contact&#39;: &#39;42&#39;, &#39;strikes_swinging&#39;: &#39;7&#39;, &#39;strikes_looking&#39;: &#39;22&#39;, &#39;inplay_gb_total&#39;: &#39;18&#39;, &#39;inplay_fb_total&#39;: &#39;10&#39;, &#39;inplay_ld&#39;: &#39;5&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;39&#39;, &#39;inherited_runners&#39;: &#39;2&#39;, &#39;inherited_score&#39;: &#39;1&#39;, &#39;wpa_def&#39;: &#39;-0.051&#39;, &#39;leverage_index_avg&#39;: &#39;0.74&#39;, &#39;re24_def&#39;: &#39;0.1&#39;}, &#39;home_pitching&#39;: {&#39;IP&#39;: &#39;9&#39;, &#39;H&#39;: &#39;7&#39;, &#39;R&#39;: &#39;3&#39;, &#39;ER&#39;: &#39;3&#39;, &#39;BB&#39;: &#39;6&#39;, &#39;SO&#39;: &#39;9&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;3.00&#39;, &#39;batters_faced&#39;: &#39;39&#39;, &#39;pitches&#39;: &#39;177&#39;, &#39;strikes_total&#39;: &#39;106&#39;, &#39;strikes_contact&#39;: &#39;59&#39;, &#39;strikes_swinging&#39;: &#39;21&#39;, &#39;strikes_looking&#39;: &#39;26&#39;, &#39;inplay_gb_total&#39;: &#39;16&#39;, &#39;inplay_fb_total&#39;: &#39;8&#39;, &#39;inplay_ld&#39;: &#39;5&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;70&#39;, &#39;inherited_runners&#39;: &#39;2&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;0.449&#39;, &#39;leverage_index_avg&#39;: &#39;1.58&#39;, &#39;re24_def&#39;: &#39;1.7&#39;}, &#39;away_pitchers&#39;: [{&#39;IP&#39;: &#39;5.2&#39;, &#39;H&#39;: &#39;8&#39;, &#39;R&#39;: &#39;4&#39;, &#39;ER&#39;: &#39;3&#39;, &#39;BB&#39;: &#39;2&#39;, &#39;SO&#39;: &#39;2&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;4.76&#39;, &#39;batters_faced&#39;: &#39;25&#39;, &#39;pitches&#39;: &#39;83&#39;, &#39;strikes_total&#39;: &#39;51&#39;, &#39;strikes_contact&#39;: &#39;32&#39;, &#39;strikes_swinging&#39;: &#39;6&#39;, &#39;strikes_looking&#39;: &#39;13&#39;, &#39;inplay_gb_total&#39;: &#39;13&#39;, &#39;inplay_fb_total&#39;: &#39;8&#39;, &#39;inplay_ld&#39;: &#39;5&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;39&#39;, &#39;inherited_runners&#39;: &#39;&#39;, &#39;inherited_score&#39;: &#39;&#39;, &#39;wpa_def&#39;: &#39;-0.061&#39;, &#39;leverage_index_avg&#39;: &#39;0.86&#39;, &#39;re24_def&#39;: &#39;-0.4&#39;, &#39;name&#39;: &#39;harvema01&#39;}, {&#39;IP&#39;: &#39;1.1&#39;, &#39;H&#39;: &#39;1&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;0&#39;, &#39;SO&#39;: &#39;1&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;5&#39;, &#39;pitches&#39;: &#39;20&#39;, &#39;strikes_total&#39;: &#39;13&#39;, &#39;strikes_contact&#39;: &#39;7&#39;, &#39;strikes_swinging&#39;: &#39;0&#39;, &#39;strikes_looking&#39;: &#39;6&#39;, &#39;inplay_gb_total&#39;: &#39;3&#39;, &#39;inplay_fb_total&#39;: &#39;1&#39;, &#39;inplay_ld&#39;: &#39;0&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;2&#39;, &#39;inherited_score&#39;: &#39;1&#39;, &#39;wpa_def&#39;: &#39;-0.022&#39;, &#39;leverage_index_avg&#39;: &#39;0.25&#39;, &#39;re24_def&#39;: &#39;0.0&#39;, &#39;name&#39;: &#39;colonba01&#39;}, {&#39;IP&#39;: &#39;1&#39;, &#39;H&#39;: &#39;0&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;0&#39;, &#39;SO&#39;: &#39;0&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;3&#39;, &#39;pitches&#39;: &#39;11&#39;, &#39;strikes_total&#39;: &#39;7&#39;, &#39;strikes_contact&#39;: &#39;3&#39;, &#39;strikes_swinging&#39;: &#39;1&#39;, &#39;strikes_looking&#39;: &#39;3&#39;, &#39;inplay_gb_total&#39;: &#39;2&#39;, &#39;inplay_fb_total&#39;: &#39;1&#39;, &#39;inplay_ld&#39;: &#39;0&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;0&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;0.032&#39;, &#39;leverage_index_avg&#39;: &#39;0.42&#39;, &#39;re24_def&#39;: &#39;0.5&#39;, &#39;name&#39;: &#39;blevije01&#39;}], &#39;home_pitchers&#39;: [{&#39;IP&#39;: &#39;6&#39;, &#39;H&#39;: &#39;2&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;3&#39;, &#39;SO&#39;: &#39;5&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;22&#39;, &#39;pitches&#39;: &#39;106&#39;, &#39;strikes_total&#39;: &#39;62&#39;, &#39;strikes_contact&#39;: &#39;32&#39;, &#39;strikes_swinging&#39;: &#39;14&#39;, &#39;strikes_looking&#39;: &#39;16&#39;, &#39;inplay_gb_total&#39;: &#39;11&#39;, &#39;inplay_fb_total&#39;: &#39;3&#39;, &#39;inplay_ld&#39;: &#39;2&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;70&#39;, &#39;inherited_runners&#39;: &#39;&#39;, &#39;inherited_score&#39;: &#39;&#39;, &#39;wpa_def&#39;: &#39;0.350&#39;, &#39;leverage_index_avg&#39;: &#39;0.92&#39;, &#39;re24_def&#39;: &#39;3.1&#39;, &#39;name&#39;: &#39;volqued01&#39;}, {&#39;IP&#39;: &#39;1&#39;, &#39;H&#39;: &#39;1&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;0&#39;, &#39;SO&#39;: &#39;0&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;4&#39;, &#39;pitches&#39;: &#39;12&#39;, &#39;strikes_total&#39;: &#39;7&#39;, &#39;strikes_contact&#39;: &#39;5&#39;, &#39;strikes_swinging&#39;: &#39;1&#39;, &#39;strikes_looking&#39;: &#39;1&#39;, &#39;inplay_gb_total&#39;: &#39;1&#39;, &#39;inplay_fb_total&#39;: &#39;3&#39;, &#39;inplay_ld&#39;: &#39;1&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;0&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;0.030&#39;, &#39;leverage_index_avg&#39;: &#39;0.59&#39;, &#39;re24_def&#39;: &#39;0.5&#39;, &#39;name&#39;: &#39;herreke01&#39;}, {&#39;IP&#39;: &#39;0.2&#39;, &#39;H&#39;: &#39;3&#39;, &#39;R&#39;: &#39;3&#39;, &#39;ER&#39;: &#39;3&#39;, &#39;BB&#39;: &#39;2&#39;, &#39;SO&#39;: &#39;1&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;40.50&#39;, &#39;batters_faced&#39;: &#39;7&#39;, &#39;pitches&#39;: &#39;29&#39;, &#39;strikes_total&#39;: &#39;16&#39;, &#39;strikes_contact&#39;: &#39;10&#39;, &#39;strikes_swinging&#39;: &#39;2&#39;, &#39;strikes_looking&#39;: &#39;4&#39;, &#39;inplay_gb_total&#39;: &#39;2&#39;, &#39;inplay_fb_total&#39;: &#39;2&#39;, &#39;inplay_ld&#39;: &#39;2&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;0&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;-0.203&#39;, &#39;leverage_index_avg&#39;: &#39;1.80&#39;, &#39;re24_def&#39;: &#39;-2.9&#39;, &#39;name&#39;: &#39;soriajo01&#39;}, {&#39;IP&#39;: &#39;0.1&#39;, &#39;H&#39;: &#39;0&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;0&#39;, &#39;SO&#39;: &#39;1&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;1&#39;, &#39;pitches&#39;: &#39;4&#39;, &#39;strikes_total&#39;: &#39;3&#39;, &#39;strikes_contact&#39;: &#39;1&#39;, &#39;strikes_swinging&#39;: &#39;2&#39;, &#39;strikes_looking&#39;: &#39;0&#39;, &#39;inplay_gb_total&#39;: &#39;0&#39;, &#39;inplay_fb_total&#39;: &#39;0&#39;, &#39;inplay_ld&#39;: &#39;0&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;2&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;0.106&#39;, &#39;leverage_index_avg&#39;: &#39;4.08&#39;, &#39;re24_def&#39;: &#39;0.4&#39;, &#39;name&#39;: &#39;hochelu01&#39;}, {&#39;IP&#39;: &#39;1&#39;, &#39;H&#39;: &#39;1&#39;, &#39;R&#39;: &#39;0&#39;, &#39;ER&#39;: &#39;0&#39;, &#39;BB&#39;: &#39;1&#39;, &#39;SO&#39;: &#39;2&#39;, &#39;HR&#39;: &#39;0&#39;, &#39;earned_run_avg&#39;: &#39;0.00&#39;, &#39;batters_faced&#39;: &#39;5&#39;, &#39;pitches&#39;: &#39;26&#39;, &#39;strikes_total&#39;: &#39;18&#39;, &#39;strikes_contact&#39;: &#39;11&#39;, &#39;strikes_swinging&#39;: &#39;2&#39;, &#39;strikes_looking&#39;: &#39;5&#39;, &#39;inplay_gb_total&#39;: &#39;2&#39;, &#39;inplay_fb_total&#39;: &#39;0&#39;, &#39;inplay_ld&#39;: &#39;0&#39;, &#39;inplay_unk&#39;: &#39;0&#39;, &#39;game_score&#39;: &#39;&#39;, &#39;inherited_runners&#39;: &#39;0&#39;, &#39;inherited_score&#39;: &#39;0&#39;, &#39;wpa_def&#39;: &#39;0.166&#39;, &#39;leverage_index_avg&#39;: &#39;4.62&#39;, &#39;re24_def&#39;: &#39;0.5&#39;, &#39;name&#39;: &#39;daviswa01&#39;}]} . Let&#39;s save our work, so we don&#39;t have to do that download again. . Important: We will be using the files saved in subsequent blog posts. Be sure to save them locally if you run this notebook online. . import pickle pickle.dump(game_data, open(&#39;game_data.pkl&#39;, &#39;wb&#39;)) . Prep Data for Modelling . The idea behind the model is that we care about the difference in the stats for our two opposing teams. So if the home team starting pitcher usually gets a lot more strikeouts than the away team&#39;s pitcher, that&#39;s the number we want to feed the model. As you saw above, we&#39;re going to be doing this for several stats. . Load data into DataFrames . The first task is to load our data into dataframes. We&#39;re going to end up with 4: . game_df: This will be our main dataframe that will eventually get fed into the model | pitching_df: This holds the pitching data, two rows per game (one for how team, one for away team). It&#39;s constructed this way because we need to be able to group our data per team. | batting_df: Same as above but for batting stats. | pitcher_df: This is the same as pitching_df, but has one row per player. We&#39;ll derive our starting pitcher stats from here. | . First, let&#39;s load our saved work. . import pickle game_data = pickle.load(open(&#39;game_data.pkl&#39;, &#39;rb&#39;)) . import pandas as pd games = [] batting = [] pitching = [] pitchers = [] for g in game_data: game_summary = g[&#39;game&#39;] # fix date game_summary[&#39;date&#39;] = game_summary[&#39;date&#39;] + &quot; &quot; + game_summary[&#39;start_time&#39;] del game_summary[&#39;start_time&#39;] # get starting pitchers game_summary[&#39;home_pitcher&#39;] = g[&#39;home_pitchers&#39;][0][&#39;name&#39;] game_summary[&#39;away_pitcher&#39;] = g[&#39;away_pitchers&#39;][0][&#39;name&#39;] # this is the field we&#39;ll train our model to predict game_summary[&#39;home_team_win&#39;] = int(g[&#39;home_batting&#39;][&#39;R&#39;])&gt;int(g[&#39;away_batting&#39;][&#39;R&#39;]) games.append(game_summary) # add all stats to appropriate lists target_pairs = [ (&#39;away_batting&#39;, batting), (&#39;home_batting&#39;, batting), (&#39;away_pitching&#39;, pitching), (&#39;home_pitching&#39;, pitching), (&#39;away_pitchers&#39;, pitchers), (&#39;home_pitchers&#39;, pitchers) ] for key, d in target_pairs: if isinstance(g[key], list): # pitchers for x in g[key]: if &#39;home&#39; in key: x[&#39;is_home_team&#39;] = True x[&#39;team&#39;] = g[&#39;game&#39;][&#39;home_team_abbr&#39;] else: x[&#39;is_home_team&#39;] = False x[&#39;team&#39;] = g[&#39;game&#39;][&#39;away_team_abbr&#39;] x[&#39;game_id&#39;] = g[&#39;game&#39;][&#39;game_id&#39;] d.append(x) else: #batting, pitching x = g[key] if &#39;home&#39; in key: x[&#39;is_home_team&#39;] = True x[&#39;team&#39;] = g[&#39;game&#39;][&#39;home_team_abbr&#39;] x[&#39;spread&#39;] = int(g[key][&#39;R&#39;]) - int(g[key.replace(&#39;home&#39;,&#39;away&#39;)][&#39;R&#39;]) else: x[&#39;is_home_team&#39;] = False x[&#39;team&#39;] = g[&#39;game&#39;][&#39;away_team_abbr&#39;] x[&#39;spread&#39;] = int(g[key][&#39;R&#39;]) - int(g[key.replace(&#39;away&#39;,&#39;home&#39;)][&#39;R&#39;]) x[&#39;game_id&#39;] = g[&#39;game&#39;][&#39;game_id&#39;] d.append(x) len(games), len(batting), len(pitching), len(pitchers) . (10684, 21368, 21368, 92026) . Game DF . This one is where we&#39;ll eventually put all of our stats . game_df = pd.DataFrame(games) #TODO: fix games that were rescheduled which become NaT after this next command game_df[&#39;date&#39;] = pd.to_datetime(game_df[&#39;date&#39;], errors=&#39;coerce&#39;) game_df = game_df[~game_df[&#39;game_id&#39;].str.contains(&#39;allstar&#39;)].copy() #don&#39;t care about allstar games game_df.head() . game_id away_team_abbr home_team_abbr date home_pitcher away_pitcher home_team_win . 0 KCA201604030 | NYM | KCR | 2016-04-03 19:38:00 | volqued01 | harvema01 | True | . 1 PIT201604030 | STL | PIT | 2016-04-03 13:15:00 | liriafr01 | wainwad01 | True | . 2 TBA201604030 | TOR | TBR | 2016-04-03 16:09:00 | archech01 | stromma01 | False | . 3 ANA201604040 | CHC | LAA | 2016-04-04 19:08:00 | richaga01 | arrieja01 | False | . 4 ARI201604040 | COL | ARI | 2016-04-04 18:42:00 | greinza01 | rosajo01 | False | . Batting DF . Stats about batting, one row per team per game . batting_df = pd.DataFrame(batting) for k in batting_df.keys(): if any(x in k for x in [&#39;team&#39;,&#39;game_id&#39;, &#39;home_away&#39;]): continue batting_df[k] =pd.to_numeric(batting_df[k],errors=&#39;coerce&#39;, downcast=&#39;float&#39;) batting_df.drop(columns=[&#39;details&#39;], inplace=True) batting_df.head() . AB R H RBI BB SO PA batting_avg onbase_perc slugging_perc ... leverage_index_avg wpa_bat_pos wpa_bat_neg re24_bat PO A is_home_team team spread game_id . 0 33.0 | 3.0 | 7.0 | 3.0 | 6.0 | 9.0 | 39.0 | 0.212 | 0.333 | 0.242 | ... | 1.58 | 0.746 | -1.195 | -1.7 | 24.0 | 15.0 | False | NYM | -1.0 | KCA201604030 | . 1 30.0 | 4.0 | 9.0 | 4.0 | 2.0 | 3.0 | 33.0 | 0.300 | 0.333 | 0.300 | ... | 0.74 | 0.488 | -0.434 | -0.1 | 27.0 | 13.0 | True | KCR | 1.0 | KCA201604030 | . 2 32.0 | 1.0 | 5.0 | 1.0 | 5.0 | 14.0 | 38.0 | 0.156 | 0.289 | 0.156 | ... | 1.27 | 0.504 | -0.935 | -3.4 | 24.0 | 11.0 | False | STL | -3.0 | PIT201604030 | . 3 28.0 | 4.0 | 9.0 | 4.0 | 5.0 | 5.0 | 36.0 | 0.321 | 0.429 | 0.464 | ... | 0.71 | 0.466 | -0.394 | 0.1 | 27.0 | 8.0 | True | PIT | 3.0 | PIT201604030 | . 4 35.0 | 5.0 | 7.0 | 5.0 | 3.0 | 16.0 | 38.0 | 0.200 | 0.263 | 0.314 | ... | 0.76 | 0.558 | -0.423 | 0.7 | 27.0 | 15.0 | False | TOR | 2.0 | TBA201604030 | . 5 rows × 24 columns . Pitching DF . Team pitching stats, one row per team per game . pitching_df = pd.DataFrame(pitching) for k in pitching_df.keys(): if any(x in k for x in [&#39;team&#39;,&#39;game_id&#39;, &#39;home_away&#39;]): continue pitching_df[k] =pd.to_numeric(pitching_df[k],errors=&#39;coerce&#39;, downcast=&#39;float&#39;) pitching_df.head() . IP H R ER BB SO HR earned_run_avg batters_faced pitches ... game_score inherited_runners inherited_score wpa_def leverage_index_avg re24_def is_home_team team spread game_id . 0 8.0 | 9.0 | 4.0 | 3.0 | 2.0 | 3.0 | 0.0 | 3.38 | 33.0 | 114.0 | ... | 39.0 | 2.0 | 1.0 | -0.051 | 0.74 | 0.1 | False | NYM | 1.0 | KCA201604030 | . 1 9.0 | 7.0 | 3.0 | 3.0 | 6.0 | 9.0 | 0.0 | 3.00 | 39.0 | 177.0 | ... | 70.0 | 2.0 | 0.0 | 0.449 | 1.58 | 1.7 | True | KCR | -1.0 | KCA201604030 | . 2 8.0 | 9.0 | 4.0 | 4.0 | 5.0 | 5.0 | 0.0 | 4.50 | 36.0 | 144.0 | ... | 48.0 | 0.0 | 0.0 | -0.069 | 0.71 | -0.1 | False | STL | 3.0 | PIT201604030 | . 3 9.0 | 5.0 | 1.0 | 1.0 | 5.0 | 14.0 | 0.0 | 1.00 | 38.0 | 141.0 | ... | 71.0 | 0.0 | 0.0 | 0.431 | 1.27 | 3.4 | True | PIT | -3.0 | PIT201604030 | . 4 9.0 | 7.0 | 3.0 | 3.0 | 1.0 | 7.0 | 1.0 | 3.00 | 36.0 | 118.0 | ... | 62.0 | 1.0 | 1.0 | 0.366 | 0.98 | 1.3 | False | TOR | -2.0 | TBA201604030 | . 5 rows × 28 columns . Pitcher DF . Individual pitching stats (starting pitchers only), one row per pitcher per game . pitcher_df = pd.DataFrame(pitchers) for k in pitcher_df.keys(): if any(x in k for x in [&#39;team&#39;,&#39;name&#39;,&#39;game_id&#39;, &#39;home_away&#39;]): continue pitcher_df[k] =pd.to_numeric(pitcher_df[k],errors=&#39;coerce&#39;, downcast=&#39;float&#39;) # filter the pitcher performances to just the starting pitcher pitcher_df = pitcher_df[~pitcher_df[&#39;game_score&#39;].isna()].copy().reset_index(drop=True) pitcher_df.drop(columns=[x for x in pitcher_df.keys() if &#39;inherited&#39; in x], inplace=True) pitcher_df.head() . IP H R ER BB SO HR earned_run_avg batters_faced pitches ... inplay_ld inplay_unk game_score wpa_def leverage_index_avg re24_def name is_home_team team game_id . 0 5.2 | 8.0 | 4.0 | 3.0 | 2.0 | 2.0 | 0.0 | 4.76 | 25.0 | 83.0 | ... | 5.0 | 0.0 | 39.0 | -0.061 | 0.86 | -0.4 | harvema01 | False | NYM | KCA201604030 | . 1 6.0 | 2.0 | 0.0 | 0.0 | 3.0 | 5.0 | 0.0 | 0.00 | 22.0 | 106.0 | ... | 2.0 | 0.0 | 70.0 | 0.350 | 0.92 | 3.1 | volqued01 | True | KCR | KCA201604030 | . 2 6.0 | 6.0 | 3.0 | 3.0 | 3.0 | 3.0 | 0.0 | 4.50 | 26.0 | 96.0 | ... | 6.0 | 0.0 | 48.0 | -0.069 | 0.90 | -0.1 | wainwad01 | False | STL | PIT201604030 | . 3 6.0 | 3.0 | 0.0 | 0.0 | 5.0 | 10.0 | 0.0 | 0.00 | 26.0 | 94.0 | ... | 0.0 | 0.0 | 71.0 | 0.329 | 1.52 | 2.9 | liriafr01 | True | PIT | PIT201604030 | . 4 8.0 | 6.0 | 3.0 | 3.0 | 1.0 | 5.0 | 1.0 | 3.38 | 32.0 | 98.0 | ... | 5.0 | 0.0 | 62.0 | 0.282 | 0.92 | 1.5 | stromma01 | False | TOR | TBA201604030 | . 5 rows × 26 columns . Calculate Differences in the Statistics . Here is where we&#39;re going to generate a bunch of columns in the game_df. Our statistical differences are going to be calculated like this: . For every downloaded statistic: calculate the average, standard deviation and skew: for time periods of 5, 10, 45, 180 and 730 days: grouped by team (or pitcher name in the case of pitchers) then shift the data so each row contains pre-game statistics then take the difference of the opposing team . That result is put into the game_df with a name like &quot;5day_R_Avg&quot;, or &quot;45Day_IP_StDev&quot;. The other dfs are done at that point. . Below are the routines to help execute the above algorithm. . import numpy as np def add_rolling(period, df, stat_columns): for s in stat_columns: if &#39;object&#39; in str(df[s].dtype): continue df[s+&#39;_&#39;+str(period)+&#39;_Avg&#39;] = df.groupby(&#39;team&#39;)[s].apply(lambda x:x.rolling(period).mean()) df[s+&#39;_&#39;+str(period)+&#39;_Std&#39;] = df.groupby(&#39;team&#39;)[s].apply(lambda x:x.rolling(period).std()) df[s+&#39;_&#39;+str(period)+&#39;_Skew&#39;] = df.groupby(&#39;team&#39;)[s].apply(lambda x:x.rolling(period).skew()) return df def get_diff_df(df, name, is_pitcher=False): #runs for each of the stat dataframes, returns the difference in stats #set up dataframe with time index df[&#39;date&#39;] = pd.to_datetime(df[&#39;game_id&#39;].str[3:-1], format=&quot;%Y%m%d&quot;) df = df.sort_values(by=&#39;date&#39;).copy() newindex = df.groupby(&#39;date&#39;)[&#39;date&#39;] .apply(lambda x: x + np.arange(x.size).astype(np.timedelta64)) df = df.set_index(newindex).sort_index() # get stat columns stat_cols = [x for x in df.columns if &#39;int&#39; in str(df[x].dtype)] stat_cols.extend([x for x in df.columns if &#39;float&#39; in str(df[x].dtype)]) #add lags df = add_rolling(&#39;5d&#39;, df, stat_cols) # this game series df = add_rolling(&#39;10d&#39;, df, stat_cols) df = add_rolling(&#39;45d&#39;, df, stat_cols) df = add_rolling(&#39;180d&#39;, df, stat_cols) # this season df = add_rolling(&#39;730d&#39;, df, stat_cols) # 2 years # reset stat columns to just the lags (removing the original stats) df.drop(columns=stat_cols, inplace=True) stat_cols = [x for x in df.columns if &#39;int&#39; in str(df[x].dtype)] stat_cols.extend([x for x in df.columns if &#39;float&#39; in str(df[x].dtype)]) # shift results so that each row is a pregame stat df = df.reset_index(drop=True) df = df.sort_values(by=&#39;date&#39;) for s in stat_cols: if is_pitcher: df[s] = df.groupby(&#39;name&#39;)[s].shift(1) else: df[s] = df.groupby(&#39;team&#39;)[s].shift(1) # calculate differences in pregame stats from home vs. away teams away_df = df[~df[&#39;is_home_team&#39;]].copy() away_df = away_df.set_index(&#39;game_id&#39;) away_df = away_df[stat_cols] home_df = df[df[&#39;is_home_team&#39;]].copy() home_df = home_df.set_index(&#39;game_id&#39;) home_df = home_df[stat_cols] diff_df = home_df.subtract(away_df, fill_value=0) diff_df = diff_df.reset_index() # clean column names for s in stat_cols: diff_df[name + &quot;_&quot; + s] = diff_df[s] diff_df.drop(columns=s, inplace=True) return diff_df . Below calculates the differences for each dataframe of stats, then merges those differences back into the main df. . df = game_df df = pd.merge(left=df, right = get_diff_df(batting_df, &#39;batting&#39;), on = &#39;game_id&#39;, how=&#39;left&#39;) print(df.shape) df = pd.merge(left=df, right = get_diff_df(pitching_df, &#39;pitching&#39;), on = &#39;game_id&#39;, how=&#39;left&#39;) print(df.shape) df = pd.merge(left=df, right = get_diff_df(pitcher_df, &#39;pitcher&#39;,is_pitcher=True), on = &#39;game_id&#39;, how=&#39;left&#39;) df.shape . (10684, 322) (10684, 697) . (10684, 1027) . Other Features . One of the other items we&#39;ll pick up from the 538 blog is pitcher rest. How long has it been since the pitcher played? Let&#39;s add that. . pitcher_df = pd.DataFrame(pitchers) # old version was filtered to just starters dates = pitcher_df[&#39;game_id&#39;].str[3:-1] pitcher_df[&#39;date&#39;] = pd.to_datetime(dates,format=&#39;%Y%m%d&#39;, errors=&#39;coerce&#39;) pitcher_df[&#39;rest&#39;] = pitcher_df.groupby(&#39;name&#39;)[&#39;date&#39;].diff().dt.days # merge into main dataframe # filter the pitcher performances to just the starting pitcher pitcher_df = pitcher_df[~pitcher_df[&#39;game_score&#39;].isna()].copy().reset_index(drop=True) home_pitchers = pitcher_df[pitcher_df[&#39;is_home_team&#39;]].copy().reset_index(drop=True) df = pd.merge(left=df, right=home_pitchers[[&#39;game_id&#39;,&#39;name&#39;, &#39;rest&#39;]], left_on=[&#39;game_id&#39;,&#39;home_pitcher&#39;], right_on=[&#39;game_id&#39;,&#39;name&#39;], how=&#39;left&#39;) df.rename(columns={&#39;rest&#39;:&#39;home_pitcher_rest&#39;}, inplace=True) away_pitchers = pitcher_df[~pitcher_df[&#39;is_home_team&#39;]].copy().reset_index(drop=True) df = pd.merge(left=df, right=away_pitchers[[&#39;game_id&#39;,&#39;name&#39;,&#39;rest&#39;]], left_on=[&#39;game_id&#39;,&#39;away_pitcher&#39;], right_on=[&#39;game_id&#39;,&#39;name&#39;], how=&#39;left&#39;) df.rename(columns={&#39;rest&#39;:&#39;away_pitcher_rest&#39;}, inplace=True) df[&#39;rest_diff&#39;] = df[&#39;home_pitcher_rest&#39;]-df[&#39;away_pitcher_rest&#39;] . Below we add some datetime features, as I generally do with time-series data like this. . df.dropna(subset=[&#39;date&#39;], inplace=True) df[&#39;season&#39;] = df[&#39;date&#39;].dt.year df[&#39;month&#39;]=df[&#39;date&#39;].dt.month df[&#39;week&#39;]=df[&#39;date&#39;].dt.isocalendar().week.astype(&#39;int&#39;) df[&#39;dow&#39;]=df[&#39;date&#39;].dt.weekday df[&#39;date&#39;] = (pd.to_datetime(df[&#39;date&#39;]) - pd.Timestamp(&quot;1970-01-01&quot;)) // pd.Timedelta(&#39;1s&#39;) #epoch time df.shape . (10535, 1036) . Save our work . import pickle pickle.dump(df, open(&#39;dataframe.pkl&#39;, &#39;wb&#39;)) . Train the Model . Finally, we get to train the model! This is just going to be a crude first run to make sure everything is working properly. We&#39;ll add the cleverest bits in the next blog post. . First, load our saved saved work . import pickle df = pickle.load(open(&#39;dataframe.pkl&#39;, &#39;rb&#39;)) df.shape . (10535, 1036) . Target encoding for remaining string features. This will effectively create a 180-day win% value in each of the team name columns. . encode_me = [x for x in df.keys() if &#39;object&#39; in str(df[x].dtype)] for x in encode_me: df[x] = df.groupby(x)[&#39;home_team_win&#39;].apply(lambda x:x.rolling(180).mean()).shift(1) . Create our test, train and validate data sets . df = df.sort_values(by=&#39;date&#39;).copy().reset_index(drop=True) X = df.drop(columns=[&#39;home_team_win&#39;, &#39;game_id&#39;]) y = df.home_team_win X_train = X[:-1000] y_train = y[:-1000] X_valid = X[-1000:-500] y_valid = y[-1000:-500] X_test = X[-500:] y_test = y[-500:] . Here&#39;s the training bit . import xgboost as xgb params = {&#39;learning_rate&#39;: 0.05,&#39;max_depth&#39;: 5} gbm = xgb.XGBClassifier(**params) model = gbm.fit(X_train, y_train, eval_set = [[X_train, y_train], [X_valid, y_valid]], eval_metric=&#39;logloss&#39;, early_stopping_rounds=10) xgb_test_preds = model.predict(X_test) xgb_test_proba = model.predict_proba(X_test)[:,1] . [0] validation_0-logloss:0.68944 validation_1-logloss:0.69111 Multiple eval metrics have been passed: &#39;validation_1-logloss&#39; will be used for early stopping. Will train until validation_1-logloss hasn&#39;t improved in 10 rounds. [1] validation_0-logloss:0.68608 validation_1-logloss:0.68908 [2] validation_0-logloss:0.68254 validation_1-logloss:0.68787 [3] validation_0-logloss:0.67960 validation_1-logloss:0.68570 [4] validation_0-logloss:0.67650 validation_1-logloss:0.68354 [5] validation_0-logloss:0.67358 validation_1-logloss:0.68344 [6] validation_0-logloss:0.67067 validation_1-logloss:0.68217 [7] validation_0-logloss:0.66788 validation_1-logloss:0.68103 [8] validation_0-logloss:0.66554 validation_1-logloss:0.68107 [9] validation_0-logloss:0.66269 validation_1-logloss:0.68044 [10] validation_0-logloss:0.66021 validation_1-logloss:0.67965 [11] validation_0-logloss:0.65762 validation_1-logloss:0.67943 [12] validation_0-logloss:0.65521 validation_1-logloss:0.67900 [13] validation_0-logloss:0.65277 validation_1-logloss:0.67913 [14] validation_0-logloss:0.65034 validation_1-logloss:0.67900 [15] validation_0-logloss:0.64802 validation_1-logloss:0.67854 [16] validation_0-logloss:0.64586 validation_1-logloss:0.67774 [17] validation_0-logloss:0.64366 validation_1-logloss:0.67702 [18] validation_0-logloss:0.64148 validation_1-logloss:0.67632 [19] validation_0-logloss:0.63917 validation_1-logloss:0.67638 [20] validation_0-logloss:0.63716 validation_1-logloss:0.67634 [21] validation_0-logloss:0.63539 validation_1-logloss:0.67684 [22] validation_0-logloss:0.63335 validation_1-logloss:0.67668 [23] validation_0-logloss:0.63147 validation_1-logloss:0.67573 [24] validation_0-logloss:0.62950 validation_1-logloss:0.67573 [25] validation_0-logloss:0.62791 validation_1-logloss:0.67601 [26] validation_0-logloss:0.62590 validation_1-logloss:0.67588 [27] validation_0-logloss:0.62407 validation_1-logloss:0.67529 [28] validation_0-logloss:0.62219 validation_1-logloss:0.67558 [29] validation_0-logloss:0.62030 validation_1-logloss:0.67566 [30] validation_0-logloss:0.61848 validation_1-logloss:0.67543 [31] validation_0-logloss:0.61700 validation_1-logloss:0.67507 [32] validation_0-logloss:0.61524 validation_1-logloss:0.67573 [33] validation_0-logloss:0.61374 validation_1-logloss:0.67671 [34] validation_0-logloss:0.61237 validation_1-logloss:0.67655 [35] validation_0-logloss:0.61072 validation_1-logloss:0.67682 [36] validation_0-logloss:0.60931 validation_1-logloss:0.67709 [37] validation_0-logloss:0.60811 validation_1-logloss:0.67722 [38] validation_0-logloss:0.60602 validation_1-logloss:0.67684 [39] validation_0-logloss:0.60497 validation_1-logloss:0.67666 [40] validation_0-logloss:0.60342 validation_1-logloss:0.67722 [41] validation_0-logloss:0.60194 validation_1-logloss:0.67730 Stopping. Best iteration: [31] validation_0-logloss:0.61700 validation_1-logloss:0.67507 . And our results... . from sklearn.calibration import calibration_curve from sklearn.metrics import accuracy_score, brier_score_loss import matplotlib.pyplot as plt import pickle def cal_curve(data, bins): # adapted from: #https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html fig = plt.figure(1, figsize=(12, 8)) ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2) ax2 = plt.subplot2grid((3, 1), (2, 0)) ax1.plot([0, 1], [0, 1], &quot;k:&quot;, label=&quot;Perfectly calibrated&quot;) for y_test, y_pred, y_proba, name in data: brier = brier_score_loss(y_test, y_proba) print(&quot;{} t tAccuracy:{:.4f} t Brier Loss: {:.4f}&quot;.format( name, accuracy_score(y_test, y_pred), brier)) fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=bins) ax1.plot(mean_predicted_value, fraction_of_positives, label=&quot;%s (%1.4f)&quot; % (name, brier)) ax2.hist(y_proba, range=(0, 1), bins=bins, label=name, histtype=&quot;step&quot;, lw=2) ax1.set_ylabel(&quot;Fraction of positives&quot;) ax1.set_ylim([-0.05, 1.05]) ax1.legend(loc=&quot;lower right&quot;) ax1.set_title(&#39;Calibration plots (reliability curve)&#39;) ax2.set_xlabel(&quot;Mean predicted value&quot;) ax2.set_ylabel(&quot;Count&quot;) ax2.legend(loc=&quot;lower right&quot;) plt.tight_layout() plt.show() outcomes,predictions,probabilities = pickle.load(open(&#39;baseline.pkl&#39;,&#39;rb&#39;)) data = [ (outcomes, predictions, probabilities, &#39;Casino&#39;), (y_test,xgb_test_preds, xgb_test_proba, &#39;XGBoost&#39;) ] cal_curve(data, 15) . . Casino Accuracy:0.6006 Brier Loss: 0.2358 XGBoost Accuracy:0.5780 Brier Loss: 0.2430 . That&#39;s not terrible for a first run - &gt;57% accuracy for our model vs. 60% for the casinos. We&#39;re only off by 2.2% and we still have our secret features and model optimization to do. . Our calibration is also worse, but again it&#39;s not at all terrible for our first run. I like to think of it in terms of forecasting skill. Our calibration skill is 3% worse than the casino&#39;s, as measured by our brier loss function. . This model has some promise. Let&#39;s look at the feature importances just to see which features it&#39;s using most. It looks like the model likes the game score spread , the pitching RE24 metric, and it likes the longer lags: 180day &amp; 730day. . import pandas as pd x = pd.Series(model.get_booster().get_score(importance_type= &#39;total_gain&#39;) ).sort_values() _ = x[-25:].plot(kind=&#39;barh&#39;,title=&quot;XGBoost Feature Gain&quot;) . . Next Up . In Part 3, we&#39;re going to add team power rankings and casino odds to the dataset to improve the results further! .",
            "url": "https://rdpharr.github.io/project_notes/baseball/webscraping/xgboost/brier/accuracy/calibration/2020/09/21/MLB-Part2-First-Model.html",
            "relUrl": "/baseball/webscraping/xgboost/brier/accuracy/calibration/2020/09/21/MLB-Part2-First-Model.html",
            "date": " • Sep 21, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "MLB Baseball Predictions",
            "content": "This is the second season I&#39;ve been using machine learning to make predictions and bets. Last year I made good predictions, but I hadn&#39;t figured out how to size my bets so I didn&#39;t make any money. This year I feel like I have a good strategy for this and it was solidly profitable. . I&#39;m going to share what I do in this series of blog posts. Hopefully I&#39;ll get some feedback that will help me improve. If not, at least it might help others get started. . This blog series is written in jupyter notebooks, which will show you how to build a program that predicts the outcome of MLB games. We&#39;ll be using our web scraping and machine learning skills to build a model that significantly outperforms the casino&#39;s sports books. . Each blog post, including this one, is executable. Use the buttons at the top to run the code on Binder of Colab and get fresh results for yourself. You can also download it from Github to run the notebook locally. . Important: Web scraping is dependant on other people&#8217;s web pages. If they change their site, this blog&#8217;s code will break. Don&#8217;t expect the code presented here to work forever. . Benchmarking the Sportsbooks . First thing to do is figure out how we’re going to know if we’re doing well. The most intuitive performance benchmark I found was the sportsbooks themselves. If I can make better predictions than the sportsbooks, then I should be doing well. . Downloading Sportsbook Data . We need to start by putting together a database of historic odds and outcomes for MLB games. First step is to get a list of days when games were played. We can get those from baseball-reference.com. . import requests import re import datetime as dt url = &#39;https://www.baseball-reference.com/leagues/MLB/2019-schedule.shtml&#39; resp = requests.get(url) # All the H3 tags contain day names days = re.findall(&quot;&lt;h3&gt;(.*2019)&lt;/h3&gt;&quot;, resp.text) dates = [dt.datetime.strptime(d,&quot;%A, %B %d, %Y&quot;) for d in days] print(&quot;Number of days MLB was played in 2019:&quot;, len(dates)) . Number of days MLB was played in 2019: 210 . We need the correct days because we&#39;ll be pulling the odds data from covers.com by day. Covers aggregates the published odds from several sources and then publishes a consensus moneyline. We&#39;ll grab that, along with the score of the game. Here&#39;s how we pull and parse that data. . from bs4 import BeautifulSoup as bs game_data = [] for d in dates: # get the web page with game data on it game_day = d.strftime(&#39;%Y-%m-%d&#39;) url = f&#39;https://www.covers.com/Sports/MLB/Matchups?selectedDate={game_day}&#39; resp = requests.get(url) # parse the games scraped_games = bs(resp.text).findAll(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_game_box&#39;}) for g in scraped_games: game = {} game[&#39;home_moneyline&#39;] = g[&#39;data-game-odd&#39;] game[&#39;date&#39;] = g[&#39;data-game-date&#39;] try: game[&#39;home_score&#39;] =g.find(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_list_score_home&#39;}).text.strip() game[&#39;away_score&#39;] =g.find(&#39;div&#39;,{&#39;class&#39;:&#39;cmg_matchup_list_score_away&#39;}).text.strip() except: game[&#39;home_score&#39;] =&#39;&#39; game[&#39;away_score&#39;] =&#39;&#39; game_data.append(game) if len(game_data) % 500==0: #show progress print(dt.datetime.now(), game_day, len(game_data)) print(&quot;Done! Games downloaded:&quot;, len(game_data)) . 2020-09-22 10:18:28.135002 2019-05-02 500 2020-09-22 10:18:56.497463 2019-06-08 1000 2020-09-22 10:19:23.908988 2019-07-18 1500 2020-09-22 10:19:51.687110 2019-08-24 2000 2020-09-22 10:20:19.900455 2019-10-03 2500 Done! Games downloaded: 2533 . Here&#39;s what that data looks like. You can see the moneyline was negative, meaning that the home team was favored. But the home team lost, so the prediction from the casinos was inaccurate. . game_data[0] . {&#39;home_moneyline&#39;: &#39;-155&#39;, &#39;date&#39;: &#39;2019-03-20 05:35:00&#39;, &#39;home_score&#39;: &#39;7&#39;, &#39;away_score&#39;: &#39;9&#39;} . That would have been a pretty good payout if you bet on the away team. Let&#39;s save our data so we don&#39;t need to keep downloading it. . Important: We will be using the files saved in subsequent blog posts. Be sure to save them locally if you run this notebook online. . import pickle pickle.dump(game_data, open(&#39;covers_data.pkl&#39;,&#39;wb&#39;)) . Sportsbook Accuracy . Let&#39;s see how the sportsbook did in all the games we just downloaded. . from sklearn.metrics import accuracy_score # the actual outcome of the game, true if the the home team won outcomes = [] # predictions derived from moneyline odds. True if the home team was the favorite predictions = [] # probability the home team will win, derived from moneyline odds # derived from formulas at https://www.bettingexpert.com/academy/advanced-betting-theory/odds-conversion-to-percentage probabilities = [] for d in game_data: try: moneyline = int(d[&#39;home_moneyline&#39;]) home_score = int(d[&#39;home_score&#39;]) away_score = int(d[&#39;away_score&#39;]) except: #incomplete data continue if moneyline==100: # it&#39;s rare to have a tossup since covers is averaging the odds from several sports books # but we&#39;ll exclude them from our calculations continue # convert moneyline odds ot their implied probabilities if moneyline&lt;0: probabilities.append(-moneyline/(-moneyline + 100)) elif moneyline&gt;100: probabilities.append(100/(moneyline + 100)) outcomes.append(home_score&gt;away_score) predictions.append(moneyline&lt;0) print(&quot;Sportsbook accuracy (excluding tossups): {0:.2f}%&quot;.format(100*accuracy_score(outcomes,predictions))) . Sportsbook accuracy (excluding tossups): 60.06% . That&#39;s it, right? We need a model that is better than 60% accurate. . If you plan to use this data for betting, you should have more than a win/loss prediction. To really make money, we would like to know if we think the odds of a team winning are better or worse that what the sportsbook thinks they are. Then we&#39;d be able to use some sort of expected value calculation to determine if the bet is profitable. . Sportsbook Calibration . We really want to know if we can build a model that is better calibrated than the casino&#39;s sportsbooks. Knowing our calibration will help us with bet sizing, as well as more sophisticated betting algorithms. Here&#39;s a graphical view of the calibration of the casino sports book data. . from sklearn.calibration import calibration_curve from sklearn.metrics import accuracy_score, brier_score_loss import matplotlib.pyplot as plt def cal_curve(data, bins): # adapted from: #https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html fig = plt.figure(1, figsize=(12, 8)) ax1 = plt.subplot2grid((3, 1), (0, 0), rowspan=2) ax2 = plt.subplot2grid((3, 1), (2, 0)) ax1.plot([0, 1], [0, 1], &quot;k:&quot;, label=&quot;Perfectly calibrated&quot;) for y_test, y_pred, y_proba, name in data: brier = brier_score_loss(y_test, y_proba) print(&quot;{} tAccuracy:{:.4f} t Brier Loss: {:.4f}&quot;.format( name, accuracy_score(y_test, y_pred), brier)) fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_proba, n_bins=bins) ax1.plot(mean_predicted_value, fraction_of_positives, label=&quot;%s (%1.4f)&quot; % (name, brier)) ax2.hist(y_proba, range=(0, 1), bins=bins, label=name, histtype=&quot;step&quot;, lw=2) ax1.set_ylabel(&quot;Fraction of positives&quot;) ax1.set_ylim([-0.05, 1.05]) ax1.legend(loc=&quot;lower right&quot;) ax1.set_title(&#39;Calibration plots (reliability curve)&#39;) ax2.set_xlabel(&quot;Mean predicted value&quot;) ax2.set_ylabel(&quot;Count&quot;) ax2.legend(loc=&quot;lower right&quot;) plt.tight_layout() plt.show() data = [(outcomes, predictions, probabilities, &#39;SportsBook&#39;)] cal_curve(data, 15) . . SportsBook Accuracy:0.6006 Brier Loss: 0.2358 . The graph above tells us several things about the calibration of the casino&#39;s predictions. The reliability curve clearly shows that the casino is highly calibrated. Interestingly, it looks like the blue line is shifted down slightly from the &quot;perfectly calibrated&quot; line. It would be a better fit if it was 0.05 higher. This may account for the house advantage. . The histogram below shows what portion of the games fall into each bin. We see a slight predicted advantage to the home team, with more than 50% of the observations above the 50% mark. Otherwise it looks pretty normally distributed. . Above, I said the reliability curve looks highly calibrated. If we are to judge our own efforts against the sportsbook, we can&#39;t just be eyeballing this graph all the time. A metric would be nice. One metric that is suited for calibration measurement is the Brier Score, which I&#39;ll be using to measure the model effectiveness going forward. Getting a model that scores less than 0.2358 is the target for our efforts. . Before we go, we should save the files for our baseline... . import pickle pickle.dump((outcomes,predictions, probabilities), open(&#39;baseline.pkl&#39;,&#39;wb&#39;)) . Next Up . Next, we&#39;ll start building out our historic data and training the model using XGBoost and LightGBM. .",
            "url": "https://rdpharr.github.io/project_notes/baseball/benchmark/webscraping/brier/accuracy/calibration/2020/09/20/baseball_project.html",
            "relUrl": "/baseball/benchmark/webscraping/brier/accuracy/calibration/2020/09/20/baseball_project.html",
            "date": " • Sep 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m a semi-retired tech professional, living in Las Vegas, Nevada. I’m forever in school, right now at University of the People. I do work to end racial injustices, focusing on criminal justice reform with Mass Liberation of Nevada. . You can get in touch with me using the links at the bottom of this page. . About the Site . This website is powered by fastpages. .",
          "url": "https://rdpharr.github.io/project_notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rdpharr.github.io/project_notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}